[ { "title": "Clean Architecture Take Away Part 1", "url": "/posts/Clean-Architecture-Take-Away-Part-1/", "categories": "Blogging", "tags": "Clean Architecture, C#, Code", "date": "2024-05-14 00:00:00 -0500", "snippet": "The Take awayOver the last few months, I have reviewed clean architecture, the book, and various codebases. Then, I engaged with the tech community around me on Twitter. Currently, my takeaway is that clean architecture is just an implementation of software principles, allowing for the adoption of various architectural styles such as layered, service-based, and event-driven.Many people I discussed with, who were not fans of clean architecture, still pointed to many of the same principles that clean architecture promotes. To do this, I had to play as a conscientious objector in the Uncle Bob War. I am here for the software views only. That aspect colored many people’s views on the phrase “clean architecture.” My response most of the time was “Never meet your heroes” or “Chew the meat and spit out the bones.”Many people who have videos talking about clean architecture would implement CQRS. When I first started learning about clean architecture, I mistakenly thought that was it. Now I think CQRS is just a popular way to demonstrate the design principles of clean architecture, namely SRP (The Single Responsibility Principle), OCP (The Open Closed Principle), LSP (The Liskov Substitution Principle), ISP (The Interface Segregation Principle), and the most important principle, DIP (The Dependency Inversion Principle).The book “Dependency Injection: Principles, Practices, and Patterns” states DIP as follows: “The Principle states that higher-level modules in our applications shouldn’t depend on lower-level modules; instead, modules of both levels should depend on abstractions.” Also, “The relationship between the dependency inversion principle and dependency injection is that DIP prescribes what we would like to accomplish. Not only does the Principle prescribe loose coupling, it states that abstractions should be owned by the module using the abstraction. In this context, owned means that the consuming module has control over the shape of the abstraction, and it is distributed with that module, rather than with the module that implements it.”Bringing it back to my thoughts about clean architecture: In the core section, if you have an email interface that is used in handlers, Core owns the abstraction and is used all over; it lives in the core. The implementation happens in the infrastructure section and is attached to a class that implements it. The handlers in the core never talk to the class implementing the email functionality.That makes sense but how would this same thing work in Python?" }, { "title": "Minimal APIs in C#: A Step Past the Beginner’s Guide", "url": "/posts/Minimal-API-A-Step-Past-The-Beginners-Guide/", "categories": "Blogging, API", "tags": "C#, Minimal, Python, JS", "date": "2023-06-12 00:00:00 -0500", "snippet": "Introduction:Being in the C# space for over six plus years. You get in the habit of doing things the dotnet way. I personally like that dotnet is very vocal in patterns and how to structure things. With the release of dotnet 6 we have access to Minimal APIs. While C# pays my bills and is my personal favorite. (followed by swift it has been growing on me) I have used other languages. When I first saw Minimal APIs my brain just went to similar Express and Flask, example below. Both of those frameworks have been out for years. I have used both to make some cool things. So my first thought was “How do I increase the cyclomatic complexity?”Hello World Examples:const express = require(&quot;express&quot;);const app = express();app.get(&quot;/&quot;, (req, res) =&amp;gt; { res.send(&quot;Hello, World!&quot;);});app.listen(3000);var builder = WebApplication.CreateBuilder(args);var app = builder.Build();app.MapGet(&quot;/&quot;, () =&amp;gt; &quot;Hello, World!&quot;);app.Run();from flask import Flaskapp = Flask(__name__)@app.route(&quot;/&quot;)def hello_world(): return &quot;Hello, World!&quot;if __name__ == &quot;__main__&quot;: app.run()What are Minimal APIs?Minimal APIs are a simplified way to define and implement HTTP endpoints in C#. There is way more to it especially when you get into how top level statements work in all of this. I don’t use the other part of the definition from the docs, when explaining Minimal APIs. The documentation is not incorrect, but I am thinking about impact vs. intent. The intent or purpose of why this feature was released and the impact is what we achieve with it as a community. I don’t have an answer for that yet. Minimal API’s are not going to replace what we are doing now and may projects may start off as Minimal APIs then grow into a normal api project.Setting Up the Environment:To begin, you’ll need to have the following prerequisites installed on your machine: .NET 6.0 SDK or later An Integrated Development Environment (IDE) such as Visual Studio 2022 or Visual Studio Code.Creating a Minimal API Project: Open your preferred IDE and create a new C# project. Select the ASP.NET Core Web Application template. Choose the Minimal API template to create a project specifically for minimal APIs.Defining Endpoints:With a minimal API project created, it’s time to define your endpoints. Let’s start by creating a simple “Hello, World!” endpoint. Open the Program.cs file, modify it to look like the following:var builder = WebApplication.CreateBuilder(args);builder.Services.AddDbContext&amp;lt;DataContext&amp;gt;(options =&amp;gt; options.UseSqlite(builder.Configuration.GetConnectionString(&quot;DefaultConnection&quot;)));var app = builder.Build();app.UseHttpsRedirection();app.MapGet(&quot;/car&quot;, async (DataContext context) =&amp;gt; await context.Cars.ToListAsync());app.MapGet(&quot;/car/{id}&quot;, async (DataContext context, int id) =&amp;gt; await context.Cars.FindAsync(id) is Cars car ? Results.Ok(car) : Results.NotFound(&quot;Sorry, car not found.&quot;)); Note: I am not going over how to set up ef core and run a migration. I don’t want to deviate from the core point too much. Even in the example I am using sqlite just to get some data to play with. public class DataContext : DbContext { public DataContext(DbContextOptions&amp;lt;DataContext&amp;gt; options) : base(options) { } public DbSet&amp;lt;Cars&amp;gt; Cars =&amp;gt; Set&amp;lt;Cars&amp;gt;(); } public class Cars { public int Id { get; set; } public string Name { get; set; } = string.Empty; public string Make { get; set; } = string.Empty; public string Year { get; set; } = string.Empty; public int Price { get; set; } }Problem: This is one of those great clean examples. I don’t live in a clean world. How would one structure this to handle a non-trivial amount of API calls? Small projects, the requirements are going to change, there will be a few “Can we sneak this in real quickly?”.A Possible solution: Removing things from the Program file.I would start by removing the IServiceCollection items. This is something that has the possibility to grow, right now I am passing the DataContext around and that is a big no no. If I was to just add the repository pattern this section will grow.So something like this:builder.Services.AddScopped&amp;lt;ICarRepository, CarRepository&amp;gt;(); This is just one, this could also grow depending on our needs. I would hate for this to be in the Project.cs file with the API calls.First update:var builder = WebApplication.CreateBuilder(args);RegisterServices(builder.Services);var app = builder.Build();app.UseHttpsRedirection();app.MapGet(&quot;/car&quot;, async (DataContext context) =&amp;gt; await context.Cars.ToListAsync());app.MapGet(&quot;/car/{id}&quot;, async (DataContext context, int id) =&amp;gt; await context.Cars.FindAsync(id) is Cars car ? Results.Ok(car) : Results.NotFound(&quot;Sorry, car not found.&quot;));app.Run(); void RegisterServices(IServiceCollection services){ services.AddScopped&amp;lt;ICarRepository, CarRepository&amp;gt;(); services.AddDbContext&amp;lt;DataContext&amp;gt;(options =&amp;gt; options.UseSqlite(builder.Configuration.GetConnectionString(&quot;DefaultConnection&quot;)));}This is a method but this could be its own class, whatever works for us. The goal is just to remove some of the set up code from the Program.cs file.Fun Fact: The code below would have worked as well. I just made it verbose so I could move it around more if I wanted too. If you have not used top level statements this might look odd since the builder is not passed in. The way top level statements work, it is behind the scenes compiling a main and a start up class for you. So long in Program.cs builder is in scope wherever you use it.void RegisterServices(){ builder.Services.AddScopped&amp;lt;ICarRepository, CarRepository&amp;gt;(); builder.Services.AddDbContext&amp;lt;DataContext&amp;gt;(options =&amp;gt; options.UseSqlite(builder.Configuration.GetConnectionString(&quot;DefaultConnection&quot;)));}I am liking what we have going on here.I would like to pull out those map calls out of the program file. public class ClientApi { public ClientApi() { } public void Register(WebApplication app) { app.MapGet(&quot;/&quot;, () =&amp;gt; &quot;Hello, World!&quot;); app.MapGet(&quot;/hello/{name}&quot;, (string name) =&amp;gt; $&quot;Hello, {name}!&quot;); app.MapGet(&quot;/car&quot;, async (DataContext context) =&amp;gt; await context.Cars.ToListAsync()); app.MapGet(&quot;/car/{id}&quot;, async (DataContext context, int id) =&amp;gt; await context.Cars.FindAsync(id) is Cars car ? Results.Ok(car) : Results.NotFound(&quot;Sorry, car not found.&quot;)); } }After adding the ClientApi class I am fully able to reduce the Program.cs class to this.using MinimalApi;var builder = WebApplication.CreateBuilder(args);var app = builder.Build();app.UseHttpsRedirection();new ClientApi().Register(app);app.Run();void RegisterServices(IServiceCollection services){ services.AddDbContext&amp;lt;DataContext&amp;gt;(options =&amp;gt; options.UseSqlite(builder.Configuration.GetConnectionString(&quot;DefaultConnection&quot;)));}Conclusion:We could do more, we could even use reflection to get our mapping. After playing with Minimal APIs my biggest takeaway is the new freedom you get to do things your own ways. Remember, this blog post only scratches the surface of what minimal APIs can do. Continue exploring the ASP.NET Core documentation and examples to dive deeper into this exciting new feature." }, { "title": "Coupling and Cohesion", "url": "/posts/Coupling-And-Cohesion/", "categories": "Blogging, Coding Examples", "tags": "Coupling, Cohesion, C#", "date": "2023-04-29 00:00:00 -0500", "snippet": "Software design principles like coupling and cohesion play a significant role in determining the quality and maintainability of software systems. When high coupling and low cohesion exist, the software system can become challenging to maintain and modify. On the other hand, low coupling and high cohesion can make a system more adaptable, easier to comprehend, and maintain.Coupling measures how tightly connected or dependent two or more software modules or components are. High coupling between components can create rigidity in a system, where modifications in one component necessitate changes in others. Conversely, low coupling means the system components are independent, and changes to one component are less likely to impact others. To make a software system more flexible and adaptable, it is generally advisable to minimize coupling between components.Cohesion, on the other hand, measures how well the various parts of a module work together towards a common goal. High cohesion implies that all module parts serve the same purpose and have a well-defined function. Conversely, low cohesion can result in modules that perform multiple, unrelated tasks, making the code challenging to understand and maintain. It is therefore essential to ensure that each module or component in a software system has a well-defined purpose to maximize cohesion.Example:public class Customer{ private string name; private string email; private string address; private string phone; public Customer(string name, string email, string address, string phone) { this.name = name; this.email = email; this.address = address; this.phone = phone; } public string GetName() { return name; } public string GetEmail() { return email; } public string GetAddress() { return address; } public string GetPhone() { return phone; }}This class has low coupling because it is self-contained and does not depend on any other classes. It has high cohesion because all its parts are related to representing and managing a customer’s information.On the other hand, consider a class that represents a shopping cart in the same application.public class ShoppingCart{ private Customer customer; private List&amp;lt;Product&amp;gt; products; private decimal total; public ShoppingCart(Customer customer) { this.customer = customer; this.products = new List&amp;lt;Product&amp;gt;(); this.total = 0; } public void AddProduct(Product product) { products.Add(product); total += product.GetPrice(); } public void RemoveProduct(Product product) { products.Remove(product); total -= product.GetPrice(); } public decimal GetTotal() { return total; }}In the C# example given, the Customer class demonstrates low coupling and high cohesion. It is self-contained, does not rely on other classes, and all its parts are related to representing and managing customer information. On the other hand, the ShoppingCart class displays high coupling and high cohesion, as it depends on both the Customer class and the Product class, and all its parts are related to representing and managing a shopping cart.Designing software systems with low coupling and high cohesion is generally regarded as a best practice. Adhering to these design principles can make the system more flexible, easier to understand and maintain, and less prone to errors. Low coupling and high cohesion help developers create software that is easier to change, adapt, and extend, enabling them to add new features and functionality without disrupting existing code." }, { "title": "Working With WebApplicationFactory", "url": "/posts/Working-With-WebApplicationFactory/", "categories": "Blogging", "tags": "TDD, Testing, Testing Framework, C#, WebApplicationFactory, Xunit", "date": "2023-02-02 00:00:00 -0600", "snippet": "Throughout my career, I have seen the testing pyramid. I was under the impression that one should create more unit tests than integration tests with a dash of UI testing. The first part of my career. I was an automation developer. So, I only did UI testing. After moving back to the formal development side. To my shock many of the places I worked. Testing was not integral to the dev process. Personally, this burned me and added unnecessary stress to my life.That was then, now. I test software in ways that help me sleep at night. Later when a bug is found or we need to extend this feature. I noticed zero stress on my side. I can make the changes quickly and possibly improve the logic. The requirements are locked in. Finding myself on the backend of things more than the front end. Integration tests gives me more value as I am creating several moving parts.When I first started out testing my software I would tend to blur the lines between unit tests and integration tests. My unit tests may touch a few parts of the system and many would not consider them unit tests any longer. There would not be any calls to a database or service. I would mock the responses. This blurring was a compromise between testing at all and working with a client’s ci cd process.This is when I found out about the WebApplicationFactory class. I was late to the party and probably working on a legacy application. Legacy applications are sometimes my bread and butter. Staying current on new ways to test is best. Then I stumbled onto the WebApplicationFactory.How I see it To me, the WebApplicationFactory class is just an in-memory application that can handle HttpClient, in-memory DB’s it can do more tho.I am only able to use this with newer projects .net 3 plus. For me, that is not a problem as I want to distance myself from dotnet framework. One can configure test-specific implementations of services. Or override the default behavior in the WebApplicationFactory instance. This opens a TDD lane for me.Here is a simple example of using WebApplicationFactory for testing an ASP.NET Core MVC application (Full app here):using Microsoft.AspNetCore.Mvc.Testing;using Microsoft.EntityFrameworkCore;using Microsoft.Extensions.DependencyInjection;using Microsoft.Extensions.Hosting;namespace MinimalApiPlayground.Tests;internal class PlaygroundApplication : WebApplicationFactory&amp;lt;Program&amp;gt;{ private readonly string _environment; public PlaygroundApplication(string environment = &quot;Development&quot;) { _environment = environment; } protected override IHost CreateHost(IHostBuilder builder) { builder.UseEnvironment(_environment); // Add mock/test services to the builder here builder.ConfigureServices(services =&amp;gt; { services.AddScoped(sp =&amp;gt; { // Replace SQLite with in-memory database for tests return new DbContextOptionsBuilder&amp;lt;TodoDb&amp;gt;() .UseInMemoryDatabase(&quot;Tests&quot;) .UseApplicationServiceProvider(sp) .Options; }); }); return base.CreateHost(builder); }}using System.Net;using System.Net.Http.Headers;using Xunit;namespace MinimalApiPlayground.Tests;public class TodoApi{ private static readonly string _validTodosJsonFileName = &quot;todos-valid.json&quot;; private static readonly string _invalidTodosJsonFileName = &quot;todos-invalid.json&quot;; [Fact] public async Task POST_FromFile_Valid_Responds_Created() { await using var application = new PlaygroundApplication(); using var formContent = new MultipartFormDataContent(); using var fileContent = new StreamContent(File.OpenRead(_validTodosJsonFileName)); fileContent.Headers.ContentType = MediaTypeHeaderValue.Parse(&quot;application/json&quot;); formContent.Add(fileContent, &quot;todosFile&quot;, _validTodosJsonFileName); using var client = application.CreateClient(); using var response = await client.PostAsync(&quot;/todos/fromfile&quot;, formContent); var responseBody = await response.Content.ReadAsStringAsync(); Assert.Equal(HttpStatusCode.Created, response.StatusCode); Assert.NotNull(response.Headers.Location); Assert.Matches(&quot;My Todo from a file&quot;, responseBody); Assert.Matches(&quot;Another Todo from a file&quot;, responseBody); } [Fact] public async Task POST_FromFile_Invalid_Responds_BadRequest() { await using var application = new PlaygroundApplication(); using var formContent = new MultipartFormDataContent(); using var fileContent = new StreamContent(File.OpenRead(_invalidTodosJsonFileName)); fileContent.Headers.ContentType = MediaTypeHeaderValue.Parse(&quot;application/json&quot;); formContent.Add(fileContent, &quot;todosFile&quot;, _invalidTodosJsonFileName); using var client = application.CreateClient(); using var response = await client.PostAsync(&quot;/todos/fromfile&quot;, formContent); var responseBody = await response.Content.ReadAsStringAsync(); Assert.Equal(HttpStatusCode.BadRequest, response.StatusCode); Assert.Equal(response.Content.Headers.ContentType, MediaTypeHeaderValue.Parse(&quot;application/problem+json&quot;)); Assert.Matches(&quot;\\\\[1\\\\].Title&quot;, responseBody); Assert.Matches(&quot;The Title field is required&quot;, responseBody); }}Well after looking at the miniamal api’s I had one question. WebApplicationFactory expects an entry-point-class. What do I give it? That was a common question and the answer is here https://stackoverflow.com/questions/69058176/how-to-use-webapplicationfactory-in-net6-without-speakable-entry-point. There was also an answer about how to set this up inconjuction with xunit&#39;s IClassFixture.WebApplicationFactory is a valuable tool for integration testing ASP.NET Core applications. It provides a complete testing environment, including a deployed app and an in-memory server, making it much easier to set up, and run tests." }, { "title": "Using Tests To Speed up FeedBack Loop", "url": "/posts/Jumping-Into-Testing/", "categories": "blogging, testing", "tags": "C#, Unit Testing, Testing, Test Doubles, Mocks, London School, Detroit School, Collaborators, Dependencies", "date": "2022-02-02 00:00:00 -0600", "snippet": "Why Do I Even Care to Test?I have worked in a few code bases that only had tests at the center layers of the application. The team would rarely touch that code plus there is a good chance the test was stale. Any massive feature would lead to so much manual regression. We would lose up to a week of the sprint. Coming from a Q.A. background there is a process to do a manual regression. There are patterns and software that show steps as test cases. Using the software you would know what was done and you could have a pretty good estimate of how long you are doing regressions.Doing Things the Hard WayFast forward a few years. I moved over to the dev side, found myself doing two or three sprints then a massive “regression”. To be fair I worked in smaller companies so there were no Q.A. Team, C.I., or C.D. processes. No End 2 End, integration, or unit tests. For the most part, this did not bother me. I had figured this is just what you did as a software dev. After the epic was done you just spent three weeks fixing the side effects of the new feature. To be clear we were not allotted three weeks. We would just be given three days before new work was given. It would just take that long doing two things at once.flowchart TD A[Current Task] --&amp;gt; B{Is there a bug?}; B --&amp;gt;|Yes| C[Work on Bug]; C --&amp;gt; D[Eye Ball It]; D --&amp;gt; B; B ----&amp;gt;|No| E[Next task bug combo]; This was the unspoken sub workflow. Possibly error-prone and slow. Bugs just pop up.At this point in my career, I did not know much about unit testing. Other devs I worked with would say unit testing is a waste of time. Spoiler alert, it is not. One time the pressure was on us. I had two views that were full of similar business logic that needed to be worked on in parallel. Yes, I am aware views should not contain business logic but at this company. As a team, we could not spell the word “refactor”. So we just added code on top of code. No tests, just manual regressions. To verify we did not break existing functionality.My Breaking PointEach view had a jquery powered dropdown that would populate dynamic dropdowns based on an ajax call. Depending on the combination of drop dropdowns. There could be various page combinations in the same section. As you can start to see, this is just a problem waiting to happen. Not shortly after I was “done” not only did I have a few bugs to fix. The requirements changed. On paper the logic was clear, both views should act the same. The problem was both views had been created by two different consultants with two different coding styles. With zero communication between each other. One view used custom templating logic and another used a very complex nested loop with a poor naming convention. The requirements for this section changed multiple times. This was the first time I wanted tests. Both views were broken before we added code. This section of code gave me the blues. To test any of your changes you had to do a long manual process. With this long feedback loop verifying any changes was that much harder. This project put me on my testing journey. Before then I had done years of dev work without writing any tests for my work. The long feedback loop was burning me out. Fast forward to 2022 I pretty much use integration tests whenever possible.So later I got a mentor and started down my padawan journey again. I was told to do kata’s and use unit tests “File logger kata class1 class2 to keep my code structured. Now I was face to face with my unit testing ignorance. I then decided to do the zero to hero route. When I learn new things I have to learn everything so I know what to ignore later. So why even unit test? To get a workflow like this. Something like this would have told me when my changes were breaking my views.flowchart TD A[Build Process] --&amp;gt; B{Test passing?}; B --&amp;gt;|No| C[Work on Bug]; C --&amp;gt; D[Run test]; D --&amp;gt; B; B ----&amp;gt;|yes| E[Nothing/Next Task]; Here the system checks for breaking changes if set up correctly. Bugs come to you!compiling test knowledgeWell, code tends to deteriorate each time it is changed. You don’t know if you are introducing new problems. Even at this moment, unit tests seemed like a magical thing that would keep my code clean. I was not aware that tests only work in one direction. If you can not unit test the code, it is low quality. In the same breath. Just because you can unit test the code doesn’t mean it is quality code.Ok so now I am a tester there are two paths I could go down classical and London. Both styles verify a piece of code, both do it quickly and in an isolated manner. Now what isolated means is where the paths start to differ. London style you want to focus on the class under test as much as possible. Any dependencies you would want to mock or use test doubles.public class Engine { private CarPart _cylinder; private readonly IgpsRepository _gpsRepository; private readonly ILocationServices _locationservices; public engine() { } public engine(IgpsRepository gpsRepository, ILocationServices _locationservices, CarPar cylinder) { _cylinder = cylinder; } //.. Do things public CarAction drive(Speed speed) { // do things return carAction; }}// ... In a test class at the top part private readonly IgpsRepository _gpsRepository = Substitute.For&amp;lt;IgpsRepository&amp;gt;();private readonly ILocationServices _locationservices = Substitute.For&amp;lt;ILocationServices&amp;gt;();// ... In a test class[Fact]public void CoolTestName(){ // simple test double example var part = new CarPart(); &amp;lt;-- test double var _sut = new Engine(part); //... Test and things}[Fact]public void CoolTestName(){ // Data for mock var latitude = new Latitude { Latitude = 4, Longitude = 5 } var locaton = new Location { State = &quot;state&quot; } _gpsRepository.GetLatitude(4,5).Returns(latitude)); _locationservices.GetState(&quot;state&quot;).Returns(locaton); // Using mocks to make test doubles example var part = new CarPart(); // &amp;lt;-- test double var speed = new Speed(55); var _sut = new Engine(_gpsRepository, _locationservices, part); // &amp;lt;-- using mocks var action = _sut.drive(speed); //... Test and things Assert.NotNull(result);} There are many types of doubles Dummy, Fake, Stub, Spy and Mock to name a few.The goal here is to separate the classes heavier from any external influence. In the classical approach, we just want to do all of the unit tests in an isolated manner. We want all of the tests to avoid talking to any shared state. The classical style is looser, a unit could be a single class or a set of classes. Long as you use test doubles for any shared dependencies. After getting an understanding of my options I see the London style is not my cup of tea.public interface ICalculator{ int Add(int a, int b); string Mode { get; set; } event EventHandler PoweringUp;}// In test file [Fact]public void CoolTestName(){ // Setting up the mock calculator = Substitute.For&amp;lt;ICalculator&amp;gt;();} This is an example from the nsubstitute docs.In the past, I worked in codebases that had little to no interfaces. Using mocks would result in me creating interfaces and proxy classes to get things under test. This has to be done because mocking classes is bad practice. I will use a mock but it is a last resort. Working in messy codebases. Getting anything under test is already a challenge, I need all of the flexibility I can get. If you’re open to reading PHP this was a cool little guide to testingTest doubles are just the start of the dive into the talk of dependencies in testing. Understanding collaborators and dependencies allows you to avoid pitfalls when making tests. Just like with test doubles, there are many types of dependencies.Flavors of DependenciesThe first thing I had to wrap my head around is what dependency is. When you read something it may not click till you use it, or do some more digging. Shared, private, and out-of-process dependencies came up the most. What is a collaborator? Anything mutable. Classes like the dbContext would be a collaborator because it is providing access to the database. The DB is a shared dependency. Value types or objects can be dependencies as well. A shared dependency is a dependency used between tests and can affect each other’s outcomes. A private dependency is not shared. An out of process dependency runs outside the applications execution process. This is a rabbit hole of what’s what information." }, { "title": "Intro To DI, Aggregation Association And Composition", "url": "/posts/Intro-To-DI-Aggregation-Association-And-Composition/", "categories": "Blogging, Dependency Injection", "tags": "C#, Aggregation, Association, Composition, Inheritance, Dependency Injection", "date": "2021-10-07 00:00:00 -0500", "snippet": "Why are we hereSometimes while learning software concepts. I like to dig a few layers deeper to understand better. One of my older mentors used to say, “You have to bring books to the books sometimes.” While reading Dependency Injection principles, practices, and patterns, another book kept popping up into my head. The object-oriented thought process. The dependency injection book has been a great read. I even recommend it. Yet as my reading progressed. My early definition of dependency injection, “A set of software design principles and patterns that enables you to develop loosely coupled code.” I asked myself. What is the smaller subset of this principle? My experience in software has been. That if it is complex. You can probably break it down into smaller components.I will stop there and focus on how composition and inheritance kept popping up. I found many views on the subject. Even the object-oriented thought process book tells the reader, “the views it had could be contested.” So using that and other sources, we learn that dependency injection relies on composition. It is a way to implement Inversion Of Control. IOC it and dependency injection are related. Dependency injection is one of many ways to implement IOC. So I will stop there and focus on how composition aids us in DI.So what is composition? Why should we use it? I got many definitions depending on where I looked. Sticking with the book The object-Oriented Thought Process, they define composition as an object that is built from other objects.Why use it?First, why should we use it? We do not have many options if we want to build classes from other classes. There is inheritance and composition. Many people have issues with inheritance and are very vocal. I am not, I think it’s a tool. If it can help you, use it. If it doesn’t fit your needs don’t use it. Can’t speak for everyone but my anecdotal experience from college was you learned only inheritance. So armed with that knowledge you would force that into everything you did through inheritance. Even if it was not needed. This brought up another underlying concept of has-a vs is-a.The same way in physics you have molecules, atoms, protons, neutrons, electrons, and the army of quantum particles like quarks. Is the same way many software concepts can come together and form bigger concepts. Back to Is-a and Has-a. The Is-a relationship is represented by inheritance, this is a separate concept. Inheritance is tightly coupled to polymorphism. Let’s remember that inheritance allows a class to inherit the attributes and methods of another class. This allows the creation of brand new classes by abstracting out common attributes and behaviors. This is why when a class inherits from a parent class it is of the same type.Code example of inheritancepublic class Mammal{ public void Sleep() { Console.WriteLine(&quot;zzzz&quot;); } public void WarmBlood() { Console.WriteLine(&quot;I have warm blood&quot;); } public virtual void MakeNoise() { Console.WriteLine(&quot;kaa kaa&quot;); }}class Dog : Mammal{ public override void MakeNoise() { Console.WriteLine(&quot;Bark Bark&quot;); }}classDiagram Mammal &amp;lt;|-- Dog : Inheritance Mammal: +Sleep() Mammal: +WarmBlood() Mammal: +MakeNoise() class Dog{ +MakeNoise() }In the above example, the dog class has two types, of course, dog but mammal as well. The dog class has access to the sleep method and anything in the mammal class that is not private. That itself is the problem. The dog class is tightly coupled to the mammal class. Any changes there now affect the dog class. If this is planned. That is not a problem. Sometimes this can lead to changes being hard or unexpected behavior when the inheritance tree starts to grow.Lots of people will just say never use inheritance or favor composition over inheritance. I think this article covers why that is bad advice. Inheritance and composition are important techniques. When it comes to building OO systems. Take a moment to understand the strengths and weaknesses of both and to use each at the right times. This link here is a good example ofExample of the concept “favor composition over inheritance”?linkSo ending our talk on inheritance, remember this is not a damnation of that, just a deep dive. Back to composition.CompositionWith composition, a class has a field of another class interface or class. The relationship is has-a. With composition, you design your objects around what they do. Using the mammal dog example from above it would be structured like this.class Dog{ Mammal mammal; ...}Here we would use the mammal object to use the make MakeNoise method. The problem here is we can not override that method. So to use composition would not be the best idea but you see how it works. While a bad example causes the example above was showing you how you can override a method. This is in the spirit of what we are shooting for but we can do better.class A{}class B{ var id = new A(); id.method();}Composition is a foundation of dependency injection. Let’s drill into this more before we move on to D.I. In short, whenever a particular object is composed of other objects. Those objects are included as object fields. The new object is known as a compound, or aggregate, or composite object. There are a few flavors of composition having a has-a relationship. The two types of composition are aggregation and associations. Note that Composition is an area where the question of which came first. Some think that composition is a form of association, and others think association is a form of composition.Aggregation Association, and CompositionAggregation and composition are types of association. Based on the object-oriented thought process, “In this book, I Consider aggregation and association to be types of composition, all though there are varied opinions on this” looking at StackOverflow this is very true. This is even boiled down to just association and aggregation. The main difference being with aggregation you normally see only the whole and in associations, you normally see parts that make up the whole.A “owns” B = Composition: B has no meaning or purpose in the system without AA “uses” B = Aggregation : B exists independently (conceptually) from AA Text Editor owns a Buffer (composition). A Text Editor uses a File (aggregation). When the Text Editor is closed, the Buffer is destroyed but the File itself is not destroyed.Composition over InheritanceCovered above many blogs and posts. Many others want you to favor composition over inheritance, due to its “is-a” VS “has-a relationship”. The main issue being inheritance is overused in many situations and could lead to tight coupling. When changes in the parent class break functionality in the child classes. Then we have a design issue. What should the structure of the hierarchy look like and when new components are needed how do you integrate them into your current system.The problem with this example is not in its ability to explain contracts but in how they could be extended. If we needed a reptile with the same properties as a mammal. We would only have a few options. Make lizard a subclass of mammal. This is bad practice lizards are not warm-blooded. We would have methods that do not fully apply to us. I have personally seen this in a few code bases. Create a reptile superclass with the same properties as a mammal, this is also bad in my eyes as now we have code duplication. Moving from an is-a to a has-a relationship we move away from this complexity, the fragile base class problem.You can learn and use DI without knowing this in great depth. I just find it helps to know the tools you are using." }, { "title": "An Example of Reflection", "url": "/posts/Reflection/", "categories": "Blogging", "tags": "aspnet core, reflection", "date": "2021-04-17 00:00:00 -0500", "snippet": "Like most people during covid, I missed my coding groups!!! I use to belong to three or four groups. While they are still around none of my local branches decided to go virtual. So I expanded my options and dropped into any open C# groups. I enjoyed it. Excluding my main coding group I had not been around other non-work devs. We would have talks about bout complex things. One thing that kept popping up was refection. Most of the people I am around are more experienced than me. So every time it was brought up we would just gloss over reflection and we would all laugh about why it was used. While I was laughing, I would get lost in what came next. I understood what reflection was as a concept. Never seeing it in action or using it, limited that understanding. So enough back story this is the what is reflection post.Reflection is used when we want to operate on an object during runtime. I like to think of it as creating objects backward. Reflection is a meta-programming feature that many programming languages support. You can write code that inspects other code, the same system, or even itself. It sometimes can modify the behavior of that code or methods during runtime. That is my more technical definition. I was able to come up with that after I figured out my simple example.In reflection, we are interested in the types and members. Typically in a program, you create objects, call functions, set values for the properties of this class. When using reflection, things are different you have to construct what you are going to reflect on. We are not interested in the instance or its values, properties but we are interested in its type itself. What properties and methods it has. We can call those methods at run time.Looking at the Microsoft doc, all I have to do is use the GetType method and bam magic!! That was not enough for me. Seriously there is another link with more information. The way it is used and when to use it. Were still things that confused me. So I made a short and useless program. To use reflection to produce an action.var query = from m in typeof(string).GetMethods() where m.IsStatic == true orderby m.Name group m by m.Name into g orderby g.Count() select new { Name = g.Key, Overloads = g.Count()}; foreach(var item in query) { Console.WriteLine(item); }Here we drilled into the static string class to see how many overloads each method has then ordered them first by the number of overloads then alphabetically. This was a simple example of reflection. The GetMethods method shuffles its order each call. You would not want to depend on it without a constraint. Let’s look at more of a breakdown. A real-world use of reflection would be a unit testing framework. We are not going to create one, but look at how it works in an isolated point. The full code is here If you want to see how to implement a full framework this blog here is for you.Type personType = typeof(Person);var properties = personType.GetProperties();foreach (var item in properties){ Console.WriteLine($&quot;Property: Type: {item.PropertyType.Name} | Name: {item.Name}&quot;);}Person person = new Person();var methods = personType.GetMethods();foreach (var item in methods){ Console.WriteLine($&quot;Method: Type: {item.ReturnType.Name} | Name {item.Name}&quot;); if (item.Name == &quot;Print&quot;) { item.Invoke(person, null); }} Console.WriteLine(&quot;-------------------------------&quot;); AttributeTest(typeof(Person)); Console.ReadKey();Let’s start with the main method. We use the Type class and the typeof method. This will give us the ability to create an instance of our person type. We use the GetMethods method on that instance, now we will get all of the public methods of Person.Here we create a person class and a custom attribute. By giving it a parameter later we can use set values during our refection process. Putting the “Attribute” in the class name seems to be the standard. I am not a fan as it is a little confusing.public class RunMethodAttribute : Attribute{ public int Count { get; set; }}This is our simple class we will use as a stand in object.public class Person{ public string FirstName { get; set; } public string LastName { get; set; } public string Phone { get; set; } public int ZipCode { get; set; }}Now we are using our custom attribute, we can set values now and use them later in our reflection call. We will use ours in a loop. You can pass many things to an attribute but you are limited the doc will cover the do’s and don’ts.[RunMethod(Count = 3)]public void Print(){ Console.WriteLine($&quot;{FirstName} {LastName}&quot;);}[RunMethod(Count = 3)]public void TestMethod(){ Console.WriteLine(&quot;Hello from TestMethod&quot;);}public void Move(int newZipCode){ ZipCode = newZipCode; Console.WriteLine($&quot;{FirstName} {LastName} has been moved to {newZipCode}&quot;);}[RunMethod(Count = 1)]public void SayHi(){ Console.WriteLine($&quot;Hi {FirstName}&quot;);}Like above we are doing something similar in our linq statement. We are using the type class to get all of the methods of our passed in value of person. Because we are using the type class we can use all the type methods. We are using GetMethods and GetCustomAttribute with our favorite method typeof. Now we are only getting the methods that are of or custom attribute type RunMethodAttribute. With the Activator class I can be lazy and just use the CreateInstance method. Now we have what I would call our shell object (that is not an official term). Using the type class we are forced to use casting while looping. We can use our attributes to power our loop logic.static void AttributeTest(Type type){ // Get the methods var allMethods = type.GetMethods(); var methodsWithAttribute = allMethods.Where(m =&amp;gt; m.GetCustomAttribute(typeof(RunMethodAttribute)) != null); var obj = Activator.CreateInstance(type); foreach (var item in methodsWithAttribute) { var attribute = (RunMethodAttribute)item.GetCustomAttribute(typeof(RunMethodAttribute)); Console.WriteLine($&quot;{item.Name} run for {attribute.Count} times&quot;); for (int i = 0; i &amp;lt; attribute.Count; i++) { item.Invoke(obj, null); } }}For me looking at how something is used in the real world is helpful for me to know other times I may need it. For the longest, I was not able to say when to correctly using refection. I still can’t but I know of real-world moments like this, EF Core and the DBContext class, or loading DLLs using Assembly.LoadFile. That helps me “reflect” on the situation I am currently working on. Then know if reflection should be used." }, { "title": "The T In TDD", "url": "/posts/The-T-In-TDD/", "categories": "Blogging", "tags": "TDD, Testing, Testing Framework, C#, NUnit", "date": "2021-03-11 00:00:00 -0600", "snippet": "By this point. If you have read some of my older blog postings. You know I am a part of a programming group that is big on TDD and the DDD paradigm. My mind is all over the place and I learn 5 things at one time. During this storm of random learning. I picked up TDD while reading “Working Effectively With Legacy Code” by Michael C. Feathers.The main focus is clearly stated in the title “Test” Driven Development.If you are going to do TDD you will need to know how to test software. I did not learn about testing software in college. The many jobs I have worked at. Only a few of them had tests at all. Only when I became an automation developer was I forced into the world of testing. Even then I was still able to ignore many of the great benefits it offers.Here we are going to go over a unit testing framework. There are a lot of choices like XUnit (my personal favorite), NUnit, pytest for python (My second favorite), and Jest for javascript. In our example, we will cover NUnit. While XUnit is my favorite I need to use NUnit for work so here we go!This is more of a “how to structure” your tests. We will not go over “how” to test. Just like everything else in software, there are layers to testing. Picking a testing framework, assertion framework, and maybe a mocking framework. There could be more depending on your needs.Personally, starting something is hard. I always get hung up on best practices and structure. This post will not jump into best practices as that is a post all of its own but just lightly touch the options you have in a testing framework. This should get you started on your TDD journey.Many frameworks follow an attribute pattern. They use attributes to dictate functionality. I will cover the NUnit style. XUnit shares a history with NUnit and both are extremely popular. There are reasons to pick one over the other but that again is a post by itself. Some frameworks won’t follow the same attribute style per-se such as PyTest for python. The spirit of it is still there as Pytest will do something like @pytest.fixture above a method.There are many attributes available in a test framework. Some of the most common are fixtures, test, set up, tear down, ignore, and category. There are more options but we will narrow our focus. There is a long list and you can find all of the NUnit attributes here.Let us start with fixtures. They are to ensure that there is a known environment so test results are repeatable. In plain English, it takes a lot of work to set up a test then reset everything after the test has run. We plan to execute this test many times. So we want an easy way of making sure this process is repeatable. Below is a simple example [TestFixture] public class Tests { // ... }There are a few ways you can use to structure your fixtures depending on your needs. One of those patterns is the abstract test pattern. This is a pattern for when you want to test several implementations. You could write a test for each implementation or you could create an abstract class containing all of the tests. Then using a factory pattern you implement each concrete test. namespace UnitTestProject1 { public class TestArrayList : BaseTestStringList { protected override IList CreateList() { return new ArrayList(); } } public class TestStringCollection : BaseTestStringList { protected override IList CreateList() { return new StringCollection(); } } [TestFixture] public abstract class BaseTestStringList { private IList list; [SetUp] public void SetUp() { this.list = CreateList(); } protected abstract IList CreateList(); [Test] public void TestAdd() { object item = Guid.NewGuid().ToString(); int beforeCount = this.list.Count; this.list.Add(item); Assert.AreEqual(beforeCount + 1, this.list.Count); } [Test] public void TestContains() { object item = Guid.NewGuid().ToString(); int beforeCount = this.list.Count; this.list.Add(item); Assert.IsTrue(this.list.Contains(item)); } [Test] public void TestClear() { object item = Guid.NewGuid().ToString(); this.list.Add(item); this.list.Clear(); Assert.AreEqual(0, this.list.Count); Assert.IsFalse(this.list.Contains(item)); } } }SourceThis is just one way of using inheritance, generics, or parameterization. You can create a pattern that works for you. Depending on the language you choose to use. There may be pattern limitations or you will have to structure them differently. When moving from a c# automation project to a python project. I had to rethink a lot of what I did. Eventually we threw away our page object pattern. For a more dynamic data-driven approach using JSON files.The test attribute just marks a test case. More specifically this attribute lets the test runner know this method should be run. [TestFixture] public class SuccessTests { // A simple test [Test] public void Add() { /* ... */ } .... }So there are two types of teardowns. We have the OneTimeTearDown and the TearDown. The OneTimeTearDown attribute is set on methods that run once after executing all the tests in a fixture. The TearDown, unlike the OneTimeTearDown, this attribute will trigger after the test method. OneTimeSetup is best used for costly steps like creating a database. It is more on the integration test side of things. Like everything in software, the tool is at your disposal.namespace NUnit.Tests{ [TestFixture] public class SuccessTests { [OneTimeSetUp] public void Init() { /* ... */ } [OneTimeTearDown] public void Cleanup() { /* ... */ } [Test] public void Add() { /* ... */ } }}The OneTimeSetup and SetUp attributes work the same way in reverse.The Ignore attribute will skip any test it is applied to.This is a good starting point for working with a test framework. There is more to testing than this. Remember this is more of a “how to structure” your tests. So we did not go over how to test at all. Eventually, you would want to assert that the data you get is the data you expect.When I was introduced to testing I was not aware of any framework options patterns or ways to structure my tests. Or even how to test.In the dot net space, you can unit test razor pages, controllers, and middleware. Testing things like this can help you maintain the integrity of your project as it grows or if you need to do a refactor down the line.Say you are moving from an ORM to a more traditional database setup. For whatever reason. Having tests fail while you are working on the migration. Everything is fresh and you are in the same headspace. Is a lot better than the same bug popping up 6 months later. By then you are on to something else." }, { "title": "Strategy Pattern", "url": "/posts/strategy-pattern/", "categories": "Blogging", "tags": "Strategy Pattern, Strategy, gang of 4, C#, Asp.net", "date": "2021-02-02 00:00:00 -0600", "snippet": "I joined this group to improve my programming skills and understanding of software concepts. In this group, there is a book list. One of those recommended books is Head First Design Patterns. In this book, the strategy pattern is one of the first you will encounter. Using Head First’s definition, this pattern is a family of algorithms (business logic) that encapsulates each algorithm and makes them interchangeable. Strategy lets the algorithm vary independently from clients that use it. I like the high-level explanation. I also like things to be simplified.The Subreddit explains it like I am five, which is a goldmine for me. It breaks down complex topics to gain a better understanding. It helps me personally. Let’s simplify this pattern. The first time I ran across this software pattern, my eyes glossed over. I was not a fan of the example from the book. It gets the job done, but I made my own. I made two examples; a simple and more complete version.In my first example, we will think of a website login portal. With portals, you can log in using an email, phone, or social media account. Because this is a simple example, we will stick with those three options.We have different classes with the needed logic to login to the website. Each class implements the same interface. This interface tells each class to make a method. The method signature will be the same in each class, but the business logic will vary from class to class. You can find the full code herepublic class LoginUsingEmail : IAsyncRequestStrategy { public AsyncResponse SendRequest(String url) { var asyncResponse = new AsyncResponse(); Console.WriteLine(&quot;Sent login request using email&quot;); return asyncResponse; } } // Login Using Phonepublic class LoginUsingPhone : IAsyncRequestStrategy { public AsyncResponse SendRequest(String url) { var asyncResponse = new AsyncResponse(); Console.WriteLine(&quot;Sent login request using phone&quot;); return asyncResponse; } } // Login Using Social Mediapublic class LoginUsingSocialMedia : IAsyncRequestStrategy { public AsyncResponse SendRequest(String url) { var asyncResponse = new AsyncResponse(); Console.WriteLine(&quot;Sent login request using social media&quot;); return asyncResponse; } }This was the first major take away for me. Using interfaces lets us decouple the logic. In the main method, the web application class is passed in a “How to login” value via an enum. From there, the class at runtime picks the needed class to log in. In this example, the Send Request methods are not doing anything.I was moving in the correct direction with my first example trying to follow the teachings from the Head First book “Design Principle- Program to an interface, not an implementation” and “Identify the aspects of your application that vary and separate them from what stays the same.”This is the end of the simple example, but it has its issues. In my example, the switch statements are vague and super high level. With real logic, they may no longer be as nice as they are now. There could be variations or new cases, and things can start to get bad. We will want to avoid switch creep.public AsyncResponse SendAsyncRequestToServer(string url) { IAsyncRequestStrategy asyncRequestStrategy; AsyncResponse asyncResponse = null; switch (_loginType) { case LoginType.Email: asyncRequestStrategy = new LoginUsingEmail(); return asyncRequestStrategy.SendRequest(url); case LoginType.Phone: asyncRequestStrategy = new LoginUsingPhone(); return asyncRequestStrategy.SendRequest(url); case LoginType.SocialMediaAccount: asyncRequestStrategy = new LoginUsingSocialMedia(); return asyncRequestStrategy.SendRequest(url); } return asyncResponse; }Nasty code could get placed into this section, and it could become a pain point.Now this version would be more in line with the pattern from the book.using System;namespace Fixed_Strategy{ class MainApp { static void Main() { Login login; // Three contexts following different strategies login = new Login(new LoginUsingEmail()); login.LoginWebsite(); login = new Login(new LoginUsingPhone()); login.LoginWebsite(); login = new Login(new LoginUsingSocialMedia()); login.LoginWebsite(); // Wait for user Console.ReadKey(); } } abstract class LoginStrategy { public abstract void SendLoginRequest(); } class LoginUsingEmail : LoginStrategy { public override void SendLoginRequest() { Console.WriteLine( &quot;Logging in using LoginUsingEmail&quot;); } } class LoginUsingPhone : LoginStrategy { public override void SendLoginRequest() { Console.WriteLine( &quot;Logging in using LoginUsingPhone&quot;); } } class LoginUsingSocialMedia : LoginStrategy { public override void SendLoginRequest() { Console.WriteLine( &quot;Logging in using LoginUsingSocialMedia&quot;); } } class Login { private LoginStrategy _loginStrategy; // Constructor public Login(LoginStrategy strategy) { this._loginStrategy = strategy; } public void LoginWebsite() { _loginStrategy.SendLoginRequest(); } }}This is also simple, but without the switch statement, the main smell is removed. All logic is in a class, and to add any new rules, we would simply add a class. If you know dependency injection, you pretty much know Strategy Pattern!" }, { "title": "Growing as a dev during covid", "url": "/posts/Growing-as-a-dev-during-covid/", "categories": "Blogging", "tags": "Covid, Working From Home, Growth, Slacker", "date": "2021-01-15 00:00:00 -0600", "snippet": "My first free form blog post is not going to be 100% technical. I knew this time would come. Throughout my short career, I have always seen this similar conversation pop up in some way, “How good of a developer is x”? In casual conversation or typically after a job interview. At the time of this writing, there is a global pandemic going on. So a lot of people are working from home. That made me think of my skills and how do you work out your “coding muscles”. I will share a little bit about how I increased my skills.I have never been a fan of indiscriminate coding for the sake of coding. The older I get, the more I cherish time. I no longer just make random apps for the sake of making apps. Using technologies I will never touch again. Remember angular js? I had a phase where that was all I touched in my spare time. I don’t remember much of it now and many of the older projects couldn’t generate any revenue if I tried. Plus they threw that version out and made “angular 2”. I saw blood.Narrowing my focus and staying motivated was the cure from that hump. Learning how to learn was a task in itself. Learning the tools that I use every day and building those skills gave me motivation. As I saw improvement in my day to day job. Making a list of things that did not make sense and just looking them up later. Simple but effective. That gave me the energy to learn things I did not understand. Giving myself 15 minutes of just looking at something uninterrupted was my second task.After programming for 8 hours at work. The last thing I wanted to do was more coding. Especially code that I don’t understand. Soon I noticed 15 minutes turned into 30 and then to an hour and so forth. I was training myself to stay on task. After that, I realized I could start breaking things down and make a plan for compounded learning.So now I am learning things that are useful in my daily life, creating tasks and working on them for a prolonged period uninterrupted. The last thing I was missing was a community. This was so helpful. I wish I knew about this sooner in life. Being around other developers, you learn through osmosis and you get tips on things you didn’t even know you needed. So bringing this full circle to the original topic, growing as a developer during covid when working from home is the norm.It’s as simple as making a plan for yourself and making small changes over time. Achieving personal milestones and finding a community that pushes you. It is always the simple things that have the most impact." }, { "title": "Looking at the Prototype", "url": "/posts/JavaScript-Prototype/", "categories": "Blogging, Tutorial", "tags": "prototype, JavaScript, Prototype Chain, Prototype Chain, __proto__", "date": "2020-12-07 00:00:00 -0600", "snippet": "Why I care about the prototypeTo work with a lot of the cool flashy js frameworks, I was told to understand JavaScript first. Other than the scope of “this” one other concept would confuse me. The idea of prototypes would pop up, and people would always say “Don’t worry about that. It is important but not really”. So for the longest, I just ignored the prototype. I could get what I needed and not really have to worry about it. After taking a real dive into es6 and understanding classes and inheritance.The breakdownI was noticing that JavaScript was playing by different rules than C# or Java. Side note: I do Java sometimes when needed but not as I used to back in college. Back in my day, Java was the golden child, and we implemented in it. The C++ religion was dying down, and this took its place. It is interesting to see the same pattern happen with python. My professor Dr. Hang Chen (a very sharp man who took little bs. Then there was me, and I had a ton to give) at the time had the view that using Java was making us softer coders and real coders used C++ or C. It is just funny to see this same idea come up in a new era with js and python versus other compiled languages. Okay back to prototypes. I was attacking this with the mindset of a Java/C# coder.The WhatPrototypical languages are just different. Now that I have a better understanding of them, I think they are kind of cool. So step one was understanding classical then prototypal inheritance. It took a second to understand that inheritance is different in this language and how simple it is. In JavaScript, all objects including functions have a prototype property. In the diagram above. The property is just a reference to another object we called proto. It would be an object that could stand on its own and could be independent if needed. So when you are calling prop 2 it is not on the object but it is actually on the object’s prototype. That prototype object can also point to another object. Each object can have its prototype. Let’s use some code to see an example of the prototype chain. The prototype chain deals with where we have access to a property or method amid a sequence of objects. Those connected by this prototype property, here we are calling proto. The JavaScript engine will do the work for us by searching the prototype chain. We do not have to be explicit with our calls (Ex: we can just say object.prop2 and not object.proto.prop2) Let’s see an example of this.The CodeHere we created two objects with default values and a default function. The second object will have two properties with no function.// Let&#39;s create a car object with some Default valuesvar car = {make: &#39;Default&#39;,model: &#39;Default&#39;,getCarInfo: function() {return this.make + &#39; &#39; + this.model; }}var Volvo = {make: &#39;Volvo&#39;,model: &#39;S80&#39;}Don’t do this in real life. Learn about the proto here. We read docs around here. Now Volvo inherits from car. So when calling a method that doesn’t exist on Volvo it will go to Car to find itVolvo.__proto__ = car;// Now we can use the getCarInfo()console.log(Volvo.getCarInfo());We get the value of “Volvo” because of the prototype chain. It first looks on the Volvo object for that property, finds it then stops. JavaScript engine starts at the top of the chain, works its way down till it finds the needed value.console.log(Volvo.make);This will return “Honda Default” as the object has a value for make but not for model. So the prototype is car and finds the model value of Defaultvar Honda = { make: &#39;Honda&#39; }Honda.__proto__ = car;console.log(Honda.getCarInfo());Here we will crate a new function on the car object to hammer home the idea.car.getCarFullInfo = function() { return this.model + &#39;, &#39; + this.make; }console.log(Volvo.getCarFullInfo());console.log(Honda.getCarFullInfo());The value you would get here would be “S80, Volvo” and “Default, Honda” because of how prototypes work. Get the full code here." }, { "title": "A Deeper Dive Into SQL", "url": "/posts/a-deeper-dive-into-sql/", "categories": "Blogging", "tags": "SQL, Microsoft, SQL Server, Relational Model", "date": "2020-11-18 00:00:00 -0600", "snippet": "To me, SQL was a strange language at first. The basics will get you far. I am the kind of person who needs to know how the insides of something works. Tends to help me utilize the tool better sometimes. For the longest, I was able to do simple selects, queries, updates, queries, and some joins. That was more than enough to get my common daily tasks done.The longer I worked in development, the expectations of my skills increased as well. I quickly found out working with relational databases required a different thought process than my frontend work or server-side middleware work did. When I found out breakpoints did not stop the query and show all of the information at hand. I figured it was time to learn SQL. So, when in doubt, always go back to the basics. I went all the way back to my college training. I wanted to know the full SQL process.I did not go over Relational Algebra or Relational Calculus. That seemed too technical. Learning the life cycle of a SQL query seemed like a good start.The SQL query logical processing orderThe query processing order has a unique flow as it is not top-down like a lot of other languages. The order is as follows From (Source Data) Where (Row filters) Group By (Grouping) Having (Group Filter) Select (Return Expressions) Order By (Presentation Order) Offset Fetch (Paging)This was my first step in understanding the flow of a query and how to get the correct data back. Moving away from ad hoc SQL query writing was a breath of fresh air. Now I had gotten the foundation laid out. The next thing on my list was joining.How Joins work under the hoodCartesian products Every join begins with a cartesian product. A cartesian product is where each row from one set is paired with each row from the other. This will give you a set that consists of all columns from both sources.Qualified joins Inner and outer joins are both qualified joins. The qualification predicate is specified using the ON keyword. So, each row from the cartesian product is evaluated using the predicate. Only when the predicate evaluates to true will move on. All the other rows are eliminated from the set. With inner joins, the processing stops at this point and the rows are passed to the next clause. If the requested join type is an outer join, the qualified rows move on to the reservation stage. With outer joins, one or both source sets are designated as reserved. Reserved sets get to have all of the rows added to the join even those that did not pass the qualification step. So, an outer join reserves the set on the left side. So, the values on the left come back, and the nulls are placed on the right side. With right outer joins the same thing happens just flipped. Full outer joins simply reserve both sets. (NOTE this may be off or under-explained but it’s the way I worded it for myself) A more correct way would be to say Right and Left joins are different in the data that is displayed based on the ON keyword. Left joins will use the left table and empty values from the right side show as null. Vice versa for the Right joins. What I was able to find out was using the left outer join as the example. A left outer join reserves the set on the left side. here it is set a, so all its rows that failed to qualify are reintroduced back into the join result since these rows had no match in set b there is no value to show for it and a null indicator is used for this inapplicable data.Join OrderWhen joining multiple data sets, if you are exclusively working with inner joins, the order they are joined doesn’t matter. This is not the case with outer joins, the order matter. To play with join the order we have the concept of chiastic order." }, { "title": "Quick Debug Rundown", "url": "/posts/Quick-Debug-Rundown/", "categories": "Blogging, Tutorial", "tags": "Quality Assurance, Debugging, Breakpoints", "date": "2020-09-07 00:00:00 -0500", "snippet": "Debugging is a major part of software development. Not only do you create new modules, but you must also maintain older ones. Some jobs are more focused on new software Greenfield project. Others may walk into a mature product and the job is to keep the status quo.So jumping right into it breakpoints and walking through programs are a lifesaver. Breakpoints are one of the best tools in your box. Seeing the object’s data at a certain place or time can solve a lot of problems. Sometimes what you expect to get passed in is passed incorrectly. Or something is updating your object after you expect it to be modified. Other times you may have to walk through the code and just see what happens at each section before you place a breakpoint for easy access.Depending on if you are debugging front end tasks or back end tasks, you should have some options to drill down to the object level and look at the program’s flow. When debugging you want to avoid guesses. Once again depending on your company, if you are using an Agile workflow this will help with your estimation technique.Depending on your debugger, you will have many common options. Step-over, step-into, breakpoints, variable watching, and more. Step-over will just walk you through the level of execution you are on. You will walk top to the bottom of the file you are currently debugging. Step-into will take you into a calling method if you are over one. If there is nothing to step into you will default to a step over. Starting with this and expanding your tool belt to use the call stack to see the programs flow, or use the intermediate window in visual studio." }, { "title": "Build an ASP.NET Core API in a Few Steps", "url": "/posts/simple-api/", "categories": "Blogging, Tutorial", "tags": "aspnet core, API, REST", "date": "2020-08-10 00:00:00 -0500", "snippet": "We are going to create a simple REST API using a compiled language. In this example we will use asp.net core to create an API Server. We will cover the post, get, put and delete actions.There are a lot of options to create an API. Python, JavaScript, Java and many others. In this example we will drink the asp.net kool aid. This ecosystem has great project generation and in the midwest it is the dominant choice for many companies.In this post, I’ll walk through building “Store API” style functionality.For those following along at home, all the code is in a GitHub repository. Each commit in the repo corresponds to a step in this post.Step 1 - Generate the projectThis assumes you have the .NET Core SDK or Visual Studio Community installed. If you have Visual Studio Community do the following:Go to File &amp;gt; New &amp;gt; Project…Select the Visual C# project category and then select ASP.NET Web Application (.NET Framework)Name your project AspNetWebApiRest and click OKSelect the Empty project template and click OK (don’t check any boxes to add core references)dotnet new webapi -o StoreApicd StoreApidotnet add package Microsoft.EntityFrameworkCore.InMemorycode -r ../StoreApiThis generates a simple ASP.NET API website. We are using an InMemory database for speedy development. This would not be a proper set up for a live site, it is not complicated to add one later.Step 2 - Build out the Domain ModelIn this step, we build a few simple classes./Models/Products.cspublic class Products{ public int Id { get; set; } public string Sku { get; set; } public string Name { get; set; } public string Description { get; set; } public decimal Price { get; set; } public bool IsAvailable { get; set; } public int CategoryId { get; set; } /// &amp;lt;summary&amp;gt; /// This is to stop a circular reference /// &amp;lt;/summary&amp;gt; [JsonIgnore] public virtual Category Category { get; set; }}/Models/User.cspublic class User{ public int Id { get; set; } public string Email { get; set; } public virtual List&amp;lt;Order&amp;gt; Orders { get; set; }}/Models/Category.cspublic class Category{ public int Id { get; set; } public string Name { get; set; } public virtual List&amp;lt;Product&amp;gt; Products { get; set; }}/Models/Order.cspublic class Order{ public int Id { get; set; } public DateTime OrderDate { get; set; } public int UserId { get; set; } /// &amp;lt;summary&amp;gt; /// This is to stop a circular reference /// &amp;lt;/summary&amp;gt; [JsonIgnore] public virtual User User { get; set; } public virtual List&amp;lt;Product&amp;gt; Products { get; set; }}Step 3 - Build out Entity Framework CoreWe will install two nuget packages to get the ball rolling.Install-Package Microsoft.EntityFrameworkCore.InMemory -Version 3.1.7AndInstall-Package Microsoft.EntityFrameworkCore -Version 3.1.7In this section we will first create the ShopContext class. Here we will add entity framework core into the project and seed the database./Models/ShopContext.cspublic class ShopContext : DbContext{ public ShopContext(DbContextOptions&amp;lt;ShopContext&amp;gt; options) : base(options) { } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&amp;lt;Category&amp;gt;().HasMany(c =&amp;gt; c.Products).WithOne(a =&amp;gt; a.Category).HasForeignKey(a =&amp;gt; a.CategoryId); modelBuilder.Entity&amp;lt;Order&amp;gt;().HasMany(o =&amp;gt; o.Products); modelBuilder.Entity&amp;lt;Order&amp;gt;().HasOne(o =&amp;gt; o.User); modelBuilder.Entity&amp;lt;User&amp;gt;().HasMany(u =&amp;gt; u.Orders).WithOne(o =&amp;gt; o.User).HasForeignKey(o =&amp;gt; o.UserId); // modelBuilder.Seed(); } public DbSet&amp;lt;Product&amp;gt; Products { get; set; } public DbSet&amp;lt;Category&amp;gt; Categories { get; set; } public DbSet&amp;lt;Order&amp;gt; Orders { get; set; } public DbSet&amp;lt;User&amp;gt; Users { get; set; }}Let us explore what is going on in this class. We will use the documentation to configure the DbContext. After that we had to tell Entity Framework the relation between those model classes. We are using the Fluent API in Entity Framework Core for our mappings mappings. You can dive deeper into how to use them here but going into detail about that concept is outside the scope of this writing.We will also add an extension method to seed the database with values/Models/ModelBuilderExtensions.csThis file is too long to give a preview for so just copy it using the link above.With all of that the project is now set up for us to start working on some crud operations. So let’s get to it.Step 4 - Build out the GETHere we are going to create the GetAllProducts and GetProduct(int id) methods. As the name implies the get all products will all of the products. The get product will use the product id to pull back that specific product.public class ProductsController : ControllerBase{ private readonly ShopContext _context; public ProductsController(ShopContext context) { _context = context; _context.Database.EnsureCreated(); } [HttpGet] public IActionResult GetAllProducts() { return Ok(_context.Products.ToArray()); } [HttpGet(&quot;{id}&quot;)] public IActionResult GetProduct(int id) { var product = _context.Products.Find(id); return Ok(product); }}We have already created our Context class. The context object is how we interact with the runtime database. Using the Find and ToArray call from the context object are the backbone of our methods.That’s it for the GET calls!!!Step 5 - Build out the POSTHere we will need some extra software to implement this. I use Insomnia but there is nothing wrong with anything else. We will use the following json to test our new code.{ &quot;name&quot;: &quot;Old Skater Jeans&quot;, &quot;sku&quot;: &quot;AWMGSYYJ&quot;, &quot;price&quot;: 68.00, &quot;isAavailable&quot;: true, &quot;categoryId&quot;: 1}Using the api client of your choice we will put that json in the body of your PUT call. We will add the following method to now receive PUTs.[HttpPost]public ActionResult&amp;lt;Product&amp;gt; PostProduct([FromBody] Product product){ _context.Products.Add(product); _context.SaveChanges(); return CreatedAtAction ( &quot;GetProduct&quot;, new { id = product.Id }, product );}With this in our controller we can accept a call and we can test this and see the update in the system. In this method we are using EF core and CreatedAtAction call. The EF is just an add for the moment and the CreatedAtAction returns a created (201) response with a location header. In another post we will add to this but for now this is a simple example.Step 6 - Build out the PUTIn this section we will work on the update portion of the api. We will use similar json but with some changes.{ &quot;name&quot;: &quot;Super Old Skater Jeans&quot;, &quot;sku&quot;: &quot;AWMGSYYZZ&quot;, &quot;price&quot;: 168.00, &quot;isAavailable&quot;: true, &quot;categoryId&quot;: 1}There are just a few updates to the name, sku and price. We will have to use the correct path to trigger a put, https://localhost:{your port number}/products/{the id of the product you want to update}. Now just so we are on the same page there should not be curly braces in your actual url. That’s just for us.We will add the new put method now.[HttpPut(&quot;{id}&quot;)]public IActionResult PutProduct([FromRoute] int id, [FromBody] Product product){ if (id != product.Id) { return BadRequest(); } _context.Entry(product).State = EntityState.Modified; try { _context.SaveChanges(); } catch (DbUpdateConcurrencyException) { if (_context.Products.Find(id) == null) { return NotFound(); } throw; } return NoContent();}Here we are working with many of the same objects, nothing new or fancy. We are using BadRequest, NotFound, and NoContent. Using EntityState we have a lot of options but it is too much to go over in this small section. From the documentation it is “Modified: the entity is being tracked by the context and exists in the database, and some or all of its property values have been modified”. That should be enough to keep us going.Step 7 - Build out the DELETEOk we are at the home stretch. The delete will act the same way as our put method. Except in our tool we will select delete instead of put to see some action.[HttpDelete(&quot;{id}&quot;)]public async Task&amp;lt;ActionResult&amp;lt;Product&amp;gt;&amp;gt; DeleteProduct(int id){ var product = await _context.Products.FindAsync(id); if (product == null) { return NotFound(); } _context.Products.Remove(product); await _context.SaveChangesAsync(); return product;}This is it for our basic api!! We will add some more changes to this project in a later post. Some of the things we will cover will be adding a full database to this, paging, filtering, searching and sorting and more. Thank you for reading!!!!And we’re done. You can see all the changes in order by looking at the commits in order.Or just see the final result at https://github.com/cmmsolutions/SimpleStoreAPI." }, { "title": "My run in with groupings", "url": "/posts/groupby/", "categories": "Blogging", "tags": "Visual Studio, C#, LINQ, IGrouping", "date": "2020-02-02 00:00:00 -0600", "snippet": "At work, I saw a collection set up that was unfamiliar to me. This collection was the IGrouping expression. At first, glance that the groupby extension was using a lambda expression to create a list of objects. The objects are sorted by the expression orederby used on the collection.That was not the full story, using my copy of “C# 6.0 in a Nutshell The Definitive Reference” their explanation is “Enumerable.GroupBy works by reading the input elements into a temporary dictionary of lists so that all elements with the same key end up in the same sublist. It then emits a sequence of grouping. A grouping is a sequence with a key property.” I looked at it as a dictionary where each key pointed to a list collection. I had planned to rewrite it. It seemed messy and bloated. At first, the explicit type of IEnumerable&amp;lt;IGrouping&amp;lt;TKey, TElement» and the looping strategy for this collection seemed like a lot. But it was the best thing to use for the structure we were passing to a pie chart view.After working with it, this is a structure I plan to use again. This site tutorials-teacher has a code snippet and an example of its usage. Update I forgot how to use it and came back to my own blog post for the win!! I also liked the example Mike Taulty gave." }, { "title": "My commonly used shortcuts", "url": "/posts/top-shortcuts/", "categories": "", "tags": "Visual Studio, C#, Windows, Windows shortcuts", "date": "2019-11-12 00:00:00 -0600", "snippet": "Below is a list of my daily drivers.This is a windows short cut that is similar to alt tab but more aesthetically pleasing.This shortcut is just muscle memory from my Linux days.Ctrl tab keeps me moving through my forty thousand open tabs." } ]
